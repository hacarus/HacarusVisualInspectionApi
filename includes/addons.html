
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>API Documentation</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .cd {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .nl {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <link href="../stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="../stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="../javascripts/all_nosearch.js"></script>
  </head>

  <body class="includes includes_addons" data-languages="[]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="../images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="toc-wrapper">
      <div class="filtered-image">
      <img src="../images/logo.png" class="logo" alt="Logo" />
      </div>
      <ul id="toc" class="toc-list-h1">
          <li>
            <a href="#t-algorithmswithversion" class="toc-h1 toc-link" data-title="Algorithm V0.7.29">Algorithm V0.7.29</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#t-algorithmoverview" class="toc-h2 toc-link" data-title="Algorithm overview">Algorithm overview</a>
                  </li>
                  <li>
                    <a href="#t-algorithmdetails" class="toc-h2 toc-link" data-title="Algorithm details">Algorithm details</a>
                      <ul class="toc-list-h3">
                          <li>
                            <a href="#t-algo1i" class="toc-h3 toc-link" data-title="Reconstructor Inspection">Reconstructor Inspection</a>
                          </li>
                          <li>
                            <a href="#t-algo2i" class="toc-h3 toc-link" data-title="Local Pattern Inspection">Local Pattern Inspection</a>
                          </li>
                          <li>
                            <a href="#t-algo3i" class="toc-h3 toc-link" data-title="Pattern Matching">Pattern Matching</a>
                          </li>
                          <li>
                            <a href="#t-algo4i" class="toc-h3 toc-link" data-title="Pattern Sample Inspection (Beta)">Pattern Sample Inspection (Beta)</a>
                          </li>
                      </ul>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#c-sdk" class="toc-h1 toc-link" data-title="C# SDK">C# SDK</a>
          </li>
          <li>
            <a href="#python-sdk" class="toc-h1 toc-link" data-title="Python SDK">Python SDK</a>
          </li>
      </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id='t-algorithmswithversion'>Algorithm V0.7.29</h1><h2 id='t-algorithmoverview'>Algorithm overview</h2>
<ul>
<li>Reconstructor Inspection

<ul>
<li>An unsupervised learning model that learns only from “OK” images (good samples, without defects, no annotation required).</li>
<li>The model can learn global texture of images.</li>
</ul></li>
<li>Local Pattern Inspection

<ul>
<li>An unsupervised learning model that learns only from “OK” images (good samples, without defects, no annotation required).</li>
<li>The model can learn local structure of images.</li>
</ul></li>
<li>Pattern Matching

<ul>
<li>Classical pattern matching algorithm which compares an image against a golden image.</li>
</ul></li>
<li>Patch Sample Inspection (Beta)

<ul>
<li>A new, generic inspection algorithm that can handle inspection objects with different placement or rotation. We have seen good inspection results and very high inspection accuracy even with difficult inspection targets across customer projects.</li>
</ul></li>
</ul>
<h2 id='t-algorithmdetails'>Algorithm details</h2><h3 id='t-algo1i'>Reconstructor Inspection</h3>
<p>An unsupervised learning model that learns only from “OK” images (good samples, without defects, annotations). At the time of prediction, a reconstruction error is calculated and abnormality defection is performed based on the magnitude. The model can learn global texture of images.
 <table class="hacarus-table"> <thead> <tr> <td><strong>Parameter</strong></td> <td><strong>Variable name</strong></td> <td><strong>Type: Range</strong></td> <td><strong>Default</strong></td> <td><strong>Impact on processing time</strong></td> <td><strong>Impact on accuracy</strong></td> <td><strong>Remarks</strong></td> </tr> </thead> <tbody> <tr><td>Model size</td><td>train_size</td><td>int : [1, inf]</td><td>10000</td><td>large -> large</td><td>large -> large</td><td>&nbsp;</td></tr> <tr><td>Minimum inspection size</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(8, 8)</td><td>large -> large</td><td>-</td><td>(4, 4) or (8, 8) or (16, 16) are empirically good.</td></tr> <tr><td>Minimum inspection step size</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>4</td><td>large -> small</td><td>large -> small</td><td>"A divisor of min_inspection_size is desirable. 1 is the most computationally intensive, but the most efficient."</td></tr> <tr><td>Dimension of feature</td><td>n_components</td><td>int : [1, inf]</td><td>10</td><td>large -> large</td><td>large->more tolerant</td><td>If the dimension of the feature amount is large, even complex objects can be reconstructed.</td></tr> <tr><td>Number of algorithm iterations</td><td>max_iter</td><td>Int : [1, inf]</td><td>10</td><td>large -> large</td><td>-</td><td>If the amount is too small, the performance will be degraded, but if it is somewhat large, the performance will not change much. Number of algorithm iterations</td></tr> <tr><td>Reconstruction error threshold</td><td>reconstruct_thresh</td><td>float : [0, inf]</td><td>2</td><td>-</td><td>large->more tolerant</td><td>A threshold for reconstruction error, about 1.5 to 3 is empirically good</td></tr> <tr><td>Threshold of anomaly</td><td>threshold</td><td>float : [0, inf]</td><td>0.1</td><td>-</td><td>large->more tolerant</td><td>&nbsp;</td></tr> <tr><td>Width from the perimeter to be ignored</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image."</td></tr> <tr><td>Minimum detection size</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>Threshold of area of detected rectangle</td></tr> <tr> <td>Anomaly range</td> <td>anomaly_range</td> <td>(float, float) : 0 to 1, 0 to 1</td> <td>(0, 1)</td> <td>-</td> <td>-</td> <td>Range used to normalize the heatmap colors in heatmap images across results.</td> </tr> </tbody></table> </p>
<h3 id='t-algo2i'>Local Pattern Inspection</h3>
<p>An unsupervised learning model that learns only from “OK” images (good samples, without defects, annotations). The model can learn local structure of images. Hence, the position alignment is required (minor gap is allowed), and the size of all images must be the same. Misalignment and rotation might be a cause of misclassification.
 <table class="hacarus-table"> <thead> <tr> <td><strong>Parameter</strong></td> <td><strong>Variable name</strong></td> <td><strong>Type: Range</strong></td> <td><strong>Default</strong></td> <td><strong>Impact on processing time</strong></td> <td><strong>Impact on accuracy</strong></td> <td><strong>Remarks</strong></td> </tr> </thead> <tbody> <tr><td>Minimum inspection size</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(32, 32)</td><td>large -> large</td><td>-</td><td>(16, 16) or (32, 32) or (64, 64) are empirically good.</td></tr> <tr><td>Minimum inspection step size</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>16</td><td>large -> small</td><td>large -> small</td><td>Half or quarter of min_inspection_size is desirable.</td></tr> <tr><td>Threshold of anomaly</td><td>threshold</td><td>float : [0, inf]</td><td>0.001</td><td>-</td><td>large->more tolerant</td><td>&nbsp;</td></tr> <tr><td>Width from the perimeter to be ignored</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image."</td></tr> <tr><td>Minimum detection size</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>Threshold of area of detected rectangle</td></tr> <tr> <td>Anomaly range</td> <td>anomaly_range</td> <td>(float, float) : 0 to 1, 0 to 1</td> <td>(0, 1)</td> <td>-</td> <td>-</td> <td>Range used to normalize the heatmap colors in heatmap images across results.</td> </tr> </tbody></table> </p>
<h3 id='t-algo3i'>Pattern Matching</h3>
<p>We calculate the golden image from “OK” images (good samples, without defects, no annotation required) and compare it to reference. Hence, the position alignment is required (position variation is not allowed), and the size of all images must be the same. Misalignment and rotation might be a cause of misclassification.
 <table class="hacarus-table"> <thead> <tr> <td><strong>Parameter</strong></td> <td><strong>Variable name</strong></td> <td><strong>Type: Range</strong></td> <td><strong>Default</strong></td> <td><strong>Impact on processing time</strong></td> <td><strong>Impact on accuracy</strong></td> <td><strong>Remarks</strong></td> </tr> </thead> <tbody> <tr> <td>Minimum inspection size	</td> <td>min_inspection_size</td> <td>(int, int) : 0~height, 0~width</td> <td>(16, 16)</td> <td>large -> large</td> <td>-</td> <td>(16, 16) or (32, 32) or (64, 64) are empirically good.</td> </tr> <tr> <td>Minimum inspection step size</td> <td>min_inspection_step</td> <td>int : [1, inf]</td> <td>4</td> <td>large -> small</td> <td></td> <td>Half or quarter of min_inspection_size is desirable.</td> </tr> <tr> <td>Threshold of anomaly</td> <td>threshold</td> <td>float : [0, inf]	0.1</td> <td>-</td> <td>large->more tolerant</td> <td></td> <td></td> </tr> <tr> <td>Width from the perimeter to be ignored</td> <td>ignore_outer</td> <td>(int, int) : 0~height, 0~width</td> <td>(0,0)</td> <td>-</td> <td>-</td> <td>The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image.</td> </tr> <tr> <td>Minimum detection size</td> <td>min_detected_area</td> <td>float : [1, inf]</td> <td>0</td> <td>-</td> <td>-</td> <td>Threshold of area of detected rectangle</td> </tr> <tr> <td>Anomaly range</td> <td>anomaly_range</td> <td>(float, float) : 0 to 1, 0 to 1</td> <td>(0, 1)</td> <td>-</td> <td>-</td> <td>Range used to normalize the heatmap colors in heatmap images across results.</td> </tr> </tbody></table> </p>
<h3 id='t-algo4i'>Pattern Sample Inspection (Beta)</h3>
<p>A new, generic inspection algorithm that can handle inspection objects with different placement or rotation. We have seen good inspection results and very high inspection accuracy even with difficult inspection targets across customer projects.
 <table class="hacarus-table"> <thead> <tr> <td><strong>Parameter</strong></td> <td><strong>Variable name</strong></td> <td><strong>Type: Range</strong></td> <td><strong>Default</strong></td> <td><strong>Impact on processing time</strong></td> <td><strong>Impact on accuracy</strong></td> <td><strong>Remarks</strong></td> </tr> </thead> <tbody> <tr> <td>Model type</td> <td>model_type</td> <td>int : [0, 1]</td> <td>0</td> <td>small -> large</td> <td>-</td> <td>0 will use a small model. 1 will use a larger model.</td> </tr> <tr> <td>Number of Features</td> <td>num_features</td> <td>int : n</td> <td>100</td> <td>large -> large</td> <td>-</td> <td>100-n are empirically good.</td> </tr> <tr> <td>Threshold of anomaly</td> <td>threshold</td> <td>float : [0, inf]	0.1</td> <td>-</td> <td>large->more tolerant</td> <td></td> <td></td> </tr> <tr> <td>Width from the perimeter to be ignored</td> <td>ignore_outer</td> <td>(int, int) : 0~height, 0~width</td> <td>(0,0)</td> <td>-</td> <td>-</td> <td>The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image.</td> </tr> <tr> <td>Minimum detection size</td> <td>min_detected_area</td> <td>float : [1, inf]</td> <td>0</td> <td>-</td> <td>-</td> <td>Threshold area of detected rectangle</td> </tr> <tr> <td>Anomaly range</td> <td>anomaly_range</td> <td>(float, float) : 0 to 1, 0 to 1</td> <td>(0, 1)</td> <td>-</td> <td>-</td> <td>Range used to normalize the heatmap colors in heatmap images across results.</td> </tr> </tbody></table> </p>
<h1 id='c-sdk'>C# SDK</h1>
<p><a href="csharp/README.html" target="_blank">Open</a></p>
<h1 id='python-sdk'>Python SDK</h1>
<p><a href="python/README.html" target="_blank">Open</a></p>

      </div>
      <div class="dark-box">
      </div>
    </div>
  </body>
</html>

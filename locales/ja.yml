ja:
  introduction: "Hacarus Visual Inspection Api"
  introductionMessage: "
  ハカルスはメーカーとメディカル事業に向け、軽量で説明可能なAIソリューションズを提供しています。
  <br/><br/>
  弊社のスパースモデリングに基づいた技術は、人間のようにデータを理解できる独自の機械学習手法です。スパースモデリングは軽量に設計されているため、コンピューティングパワー、クラウド環境、および少量の学習データなどの資源の制限された環境下で特に有用です。
  <br/><br/>
  弊社のソリューションは組み込みシステムでオフライン環境かクラウドで実行できます。伝統的なディープラーニングベースの手法に比べ、資源を効率的に使用し、よりよい結果を提供します。
  <br/><br/>
  ハカルスの外観検査ソリューションの詳細を参照するには、こちらのリンク、<a href='https://hacarus.com/ja/visual-inspection/'>https://hacarus.com/ja/visual-inspection/</a> をご覧ください。また、APIへのアクセスのリクエストは<a href='https://hacarus.com/ja/contact/'>contact us</a> までご連絡ください。
  "
  introductionMessageMoreCSharp: "この外観検査用 API wrapper for C#は、あなたのC#のプロジェクトに、APIを通じて外観検査モジュールを組み込むことができます。このライブラリはC# .Net Framework 4.6.1 と .Net Core 2.0.をサポートしています。"
  introductionMessageMorePython: "このPython用外観検査SDKは、APIを用いてハカルス外観検査モジュールを使いたいソフトウェアエンジニアのために作成しています。 このAPIによって、Pythonベースのアプリケーションに外観検査モジュールを簡単に統合することができます。"
  installation: "インストール"
  installationMessagePython: "このパッケージをインストールするために、以下のコマンドを実行してください。"
  installationMessageCSharp: "このパッケージをプロジェクトにインストールするため、こちらのコマンドをPackage Manager Consoleに入力してください。"
  installationMessageMoreCSharp: "
  NuGetパッケージマネージャを使用してプロジェクトに追加することもできます。Show prerelease packagesにチェックを入れ、 HacarusVisualInspectionApi を nuget.org のリポジトリで検索してください。
  <br/><br/>
  他のインストール方法は<a href='https://www.nuget.org/packages/HacarusVisualInspectionApi/1.1.2-beta'>Nuget Package Site</a>を参照ください。"
  terms: "用語説明"
  termsMessage: "
このドキュメントの全体で使用されている用語の簡単な説明：
<br/><br/>
<b>モデル</b><br/>
モデルは一連のパラメータの設定とともに、データセットの学習データ（トレーニングデータ）をアルゴリズムに適用して、作成・学習できます。
<br/><br/>
<b>アルゴリズム</b><br/>
アルゴリズムはモデルを構成するため使用する機械学習アルゴリズムのことです。外観検査の性質と予想される精度および性能によって選択します。
<br/><br/>
<b>学習</b><br/>
新しいモデルを作成する操作です。
<br/><br/>
<b>パラメータ</b><br/>
パラメータは、学習中にアルゴリズムを適用する方法を構成するために使用されます。 例えば、最小または最大の画像解像度などがあります。
<br/><br/>
<b>データ</b><br/>
データ（アイテムとも呼ばれる)は検査の対象となる単一の製品のデータを表します。 1つのデータに1つまたは複数の画像を関連付けることができます。
例：倉庫内の梱包箱の場合、一つの箱に6つの面の画像があります。
"
  usage: "使用方法"
  usageMessage: "
始めに、下記のものが必要です。
<ul>
  <li>
    クライエントIDとクライエントシークレット
    <ul>
      <li>
        これはSDKを認証するために使用されます。
      </li>
      <li>
        認証されたユーザーはシステム機能にアクセスでき、データを追加したり、データ、アルゴリズム、モデルの一覧を取得ことができます。
      </li>
      <li>
        モデルの学習や推論を行うためにはライセンスをアクティベートする必要があります。
      </li>
    </ul>
  </li>
  <li>
    ライセンスファイル
    <ul>
      <li>
        これはライセンスをアクティベートするため使用されます。
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    学習画像
    <ul>
      <li>
        モデルを作成するためには、画像をアップロードして、学習データを提供する必要があります。
      </li>
      <li>
        モデルを作成するには学習データが使用されます。
      </li>
      <li>
        画像をアップロードすることで推論のためのデータを追加します。
      </li>
      <li>
        作成済みのモデルを用いてデータを推論します。
      </li>
      <li>
        サンプル画像はこちらからダウンロードすることができます。（<a href='https://drive.google.com/open?id=1D736spz0rSOMgp9V71BEYtKH31Sxn1ud'>Metal Plates</a>、<a href='https://drive.google.com/open?id=14fnv6d9Cq9suUdoH57RntSuE_mh21fQg'>Wood Blocks</a>）
        <ul>
          <li>
            モデルの作成に使用できる良品と不良品の画像とパラメータの一覧が含まれています。
          </li>
          <li>
            学習用の画像はtrainフォルダにあり、推論用の画像はpredictフォルダにあります。
          </li>
          <li>
            NGとは不良品の画像、OKとは良品の画像という意味です。
          </li>
        </ul>
      </li>
    </ul>
</ul>"
  initialization: "初期化"
  initializationMessage: "
  <ul>
    <li>
      ライブラリを初期化します。
    </li>
    <li>
      エンドポイントURLをとして入力。
    </li>
    <li>
      エンドポイントが入力されていない場合、ライブラリはデフォルトのエンドポイント https://sdd.hacarus.com/api を使用します。
    </li>
    <li>
      個別のエンドポイントURLは、リクエストに応じてHacarusから提供されます。
    </li>
  </ul>
  "
  authorization: "認証"
  authorizationMessage: "
  <ul>
    <li>
      アクセストークンを作成します。
    </li>
    <li>
      クライアントIDとクライアントシークレットをパラメータとして入力する。
    </li>
    <li>
      クライアントIDとクライアントシークレットは、リクエストに応じてHacarusから提供されます。
    </li>
  </ul>"
  sampleResponse: "レスポンスの一例"
  possibleErrors: "起こり得るエラー"
  error401: " 401 Unauthorized:"
  invalidClientId: "クライアントIDが無効です。"
  invalidClientSecret: "クライアントシークレットが無効です。"
  methods: "メソッド"
  activateLicense: "ライセンスのアクティベート"
  activateLicenseMessage: "
  <ul>
    <li>
      ライセンスをアクティベートします。
    </li>
    <li>
      ライセンスファイルをパラメータとして入力してください。
    </li>
    <li>
      ライセンスはユーザーが`Train` または `Predict`というファンクションを使用する前にアクティベートしてください。
    </li>
    <li>
      ライセンスファイルを取得するには、ハカルスにご連絡ください。
    </li>
  </ul>"
  error403: "403 Forbidden:"
  invalidLicense: "ライセンスファイルが無効。"
  licenseExists: "ライセンスはアクティベート済み。"
  getVersionNumber: "バージョン番号を取得する"
  getVersionNumberMessage: "ハカルス外観検査APIの現在のバージョン番号を取得するには、このメソッドを使用します。"
  getItems: "データを取得する"
  getItemsMessage: "
  <ul>
    <li>
      学習、推論、およびアーカイブ別に分類したアップロード済みアイテムのリストを取得します。
      <ul>
        <li>
          `training`: 学習に使用するデータ
          <ul>
            <li>
              データが`%{true}`（good）、`%{false}`（defect）、または`%{null}`（ラベルなし）のいずれかにラベル付けされているかをgoodというキーで知ることができます。
            </li>
          </ul>
        </li>
        <li>
          `predict`: アップロード済みのデータのうち、推論用のもの
          <ul>
            <li>
             推論結果を確認するには、`good`と`status`のキーを確認してください。
            </li>
          </ul>
        </li>
        <li>
          `archived`: アーカイブ済みデータ（将来実装予定の機能、現在使用されていません）
        </li>
      </ul>
    </li>
    <li>
      `override_assessment`および`confirm_assessment`はUI（ユーザインタフェース）固有のものであり、SDKを使用している場合は無視できます。
    </li>
  </ul>
  "
  getAlgorithms:  "アルゴリズムを取得する"
  getAlgorithmsMessage: "
  <ul>
    <li>
      学習に使用できるアルゴリズムと使用できるパラメータの一覧をリストで返します。
    </li>
    <li>
      アルゴリズムの説明について、<a href='https://hacarus.github.io/HacarusVisualInspectionApi/#t-algorithmswithversion'>こちら</a>をご覧ください。
    </li>
  </ul>
  "
  possibleError: "起こり得るエラー"
  error404: "404 NotFound:"
  noAlgorithm: "利用可能なアルゴリズムがありません。 この問題が発生した場合はHacarusに連絡してください。"
  getModels: "モデルを取得する"
  getModelsMessage: "
  <ul>
    <li>
      データを推論するのに使用できる作成済みモデルのリストを取得します。
    </li>
    <li>
      モデルIDが渡されなかった場合（`%{serve}`メソッドを使用して）、`active`が`%{true}`のモデルをデフォルトとして使用します。
    </li>
    <li>
      `status`キーは、モデルが`active`か`failed`かを示します。
      <ul>
        <li>
          `status`が `active`のモデルは正常に作成され、予測に使用できます
        </li>
        <li>
          `status`が `failed`のモデルは作成に失敗し、予測には使用できません
        </li>
      </ul>
    </li>
  </ul>
  "
  train: "学習"
  algorithmParameter: "アルゴリズムパラメータ"
  trainMessage: "
  <ul>
    <li>
      推論に使用するモデルを作成します。
    </li>
    <li>
      モデルの学習に使用するデータIDの配列を含むオプションのパラメータを入力します。
    </li>
    <li>
      アルゴリズムの設定を調整するため%{algorithmParameter}の配列を入力します。
    </li>
    <li>
      新しく作成したモデルを確認するには、`%{getModels}`メソッドを使用します。
    </li>
  </ul>
  "
  invalidId: "少なくとも1つのデータIDがクライアントに属していないか、無効か、または存在しません。"
  addItem: "データを追加する"
  addItemMessage: "
  <ul>
    <li>
      このメソッドを使用して、学習のためのデータをアップロードしてラベルを付けます。
    </li>
    <li>
      データに良品または不良品としてラベルを付ける場合は、`%{isGood}`パラメータをブール値で`%{true}`（良品）または`%{false}`（不良品）に設定します。
    </li>
  </ul>
  "
  addItemMessageMoreCSharp: "
  <ul>
    <li>
      このメソッドを使用して、推論のためのデータをアップロードしてラベルを付けます。
    </li>
    <li>
      `Files`パラメータを使用して`FileModel`の配列を渡します。 `FileModel`は`FileName`と`ContentType`のプロパティを持ちます。
    </li>
    <li>
      FileModelを作成をするには、`FileModel File = new FileModel() `または、 `FileModel File = new FileModel(\"FileName\", \"ContentType\")`を使用してください。
    </li>
    <li>
      アップロードしたデータを確認するには、`GetItems（）`メソッドを使用します。
    </li>
    <li>
      画像のファイル名はデータID(`item_id`)として使用します。
    </li>
    <li>
      サポートされているファイル形式：`png`、`jpeg`、`tiff`
    </li>
  </ul>
  "
  addItemMessageMorePython: "
  <ul>
    <li>
      このメソッドを使用して、推論のためのデータをアップロードしてラベルを付けます。
    </li>
    <li>
      アップロードしたデータを確認するには、`get_items（）`メソッドを使用します。
    </li>
    <li>
      画像のファイル名はデータID(`item_id`)として使用します。
    </li>
    <li>
      サポートされているファイル形式：`png`、`jpeg`、`tiff`
    </li>
  </ul>
  "
  error400: "400 BadRequest:"
  invalidFile: "ファイル名かファイル形の無効。"
  noImage: "アップロード用の画像が送信されていません。"
  getItem: "特定のデータを取得する"
  getItemMessage: "
  <ul>
    <li>
      データIDで特定のデータを取得します。
    </li>
    <li>
      データIDは、アップロード時に画像ファイル名に基づいて割り当てられます。
    </li>
    <li>
      重要なキー:
      <ul>
        <li>
          `computed_assessment`: 予測の結果
        </li>
        <li>
          `annotations`: `%{serve}`メソッドが呼び出されたときに生成されるアノテーションのリストを含みます
        </li>
        <li>
          `raw_url`: アップロードされたファイルのURL
        </li>
        <li>
          `url`: 欠陥箇所表示ファイル（緑色のボックス）
        </li>
        <li>
          `status`: データのステータス。`pending`（推論前または予測中）または`done`（予測済み）のいずれか
        </li>
      </ul>
    </li>
  </ul>
  "
  itemIdDoesNotExists: "データIDが存在していません。"
  doesNotBelongToClient: " 指定されたデータIDのあるデータがクライアントに属していません。"
  predict: "予測"
  predictMessage: "
  <ul>
    <li>
      データは良品か不良品があるか推論します。
    </li>
    <li>
      結果を確認するには、`%{getItems}()`メソッドを使用して、各データの`good`キーを確認します。
    </li>
  </ul>
  "
  itemDoesNotExists: "送信されたデータとデータIDは存在していません。"
  noModel: "推論に使用できるモデルがないか、使用可能なモデルのステータスがのfailedです。 Trainメソッドを使用し、新しいモデルを作成してください。"
  genericErrors: "一般的なエラー"
  errorUnauthorized: "メソッドを呼び出すときにまだ承認されていないエラーです。エラーを遭遇する場合、最初に`%{authorize}`メソッドを呼び出してください。"
  errorNoLicense: "メソッドを呼び出すが、ライセンスがまだアクティベートされていないか期限切れになっているときのエラーです。 遭遇したら、最初に`%{activateLicense}`メソッドを呼び出してください。"
  enLink: "../"
  jaLink: "./"
  algorithmsWithVersion: アルゴリズム V0.5.1 
  algorithmOverview: アルゴリズム概要
  algorithmOverview1: Reconstructor Inspection
  algorithmOverview1i: アノテーション不要の教師なし学習アルゴリズム
  algorithmOverview1ii: 画像の全体的なテクスチャに注目し、正常画像から逸脱しているかどうか判定する。
  algorithmOverview2: Local Pattern Inspection
  algorithmOverview2i: アノテーション不要の教師なし学習アルゴリズム。
  algorithmOverview2ii: 画像の局所的な部分に注目し、正常画像から逸脱しているかどうか判定する。
  algorithmOverview3: 'Pattern Matching'
  algorithmOverview3i: 'Classical pattern matching algorithm which compares an image against a golden image.'
  algorithmOverview4: 'Patch Sample Inspection (Beta)'
  algorithmOverview4i: 'A new, generic inspection algorithm that can handle inspection objects with different placement or rotation. We have seen good inspection results and very high inspection accuracy even with difficult inspection targets across customer projects.'
  algorithmDetails: アルゴリズム詳細
  algo1i: "Reconstructor Inspection"
  algo1iText: 正常画像のみから学習するアノテーション不要の教師なし学習モデル。正常な入力画像に対して辞書学習を行う。推論時には新たな画像に対して、再構成誤差を計算し、その大小に基づいて異常検知を行う。これによって、画像の全体的なテクスチャに注目し、正常画像から逸脱しているかどうかを判定することができる。画像の位置合わせや、画像のサイズなどは特に気にしなくてもよい。
  algo1iTable: '
<table class="hacarus-table">
<thead>
  <tr>
    <td><strong>パラメータ</strong></td>
    <td><strong>変数名</strong></td>
    <td><strong>型 : 範囲</strong></td>
    <td><strong>既定値</strong></td>
    <td><strong>計算時間への影響</strong></td>
    <td><strong>精度への影響</strong></td>
    <td><strong>備考</strong></td>
  </tr>
</thead>
<tbody>
 <tr><td>学習サイズ</td><td>train_size</td><td>int : [1, inf]</td><td>10000</td><td>大 -> 大</td><td>大 -> 大</td><td>&nbsp;</td></tr>
 <tr><td>最小の検査サイズ</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(8, 8)</td><td>大 -> 大</td><td>-</td><td>(4, 4) or (8,8) or (16,16) が経験的によい。</td></tr>
 <tr><td>最小の検査サイズ幅</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>4</td><td>大 -> 小</td><td>大 -> 小</td><td>"min_inspection_sizeの約数が望ましい。1のとき一番計算負荷がかかるが、もっとも性能がよい。"</td></tr>
 <tr><td>特徴量の次元</td><td>n_components</td><td>int : [1, inf]</td><td>10</td><td>大 -> 大</td><td>"大 -> ほとんど正常</td><td>特徴量の次元が大きいと複雑な対象でも再構成できるようになる。</td></tr>
 <tr><td>アルゴリズム反復回数</td><td>max_iter</td><td>Int : [1, inf]</td><td>10</td><td>大 -> 大</td><td>-</td><td>少なすぎると性能が悪くなるが、ある程度大きければ、性能はそれほど変わらない。</td></tr>
 <tr><td>再構成誤差の閾値</td><td>reconstruct_thresh</td><td>float : [0, inf]</td><td>2</td><td>-</td><td>"大 -> ほとんど正常<br/>小 -> ほとんど異常"</td><td>再構成誤差に対する閾値、1.5 ~ 3程度の値が経験的によい</td></tr>
 <tr><td>検知領域の異常度の閾値</td><td>threshold</td><td>float : [0, inf]</td><td>0.1</td><td>-</td><td>-</td><td>大きすぎるとほとんど正常、小さすぎるとほとんど異常</td></tr>
 <tr><td>無視される外周からの幅</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"外周からの無視する領域の幅 画像の縦, 横のピクセル数までの値にする。"</td></tr>
 <tr><td>最小の検知サイズ</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>検出される矩形の面積の下限</td></tr>
</tbody>
</table>
'
  algo2i: "Local Pattern Inspection"
  algo2iText: 正常画像のみから学習するアノテーション不要の教師なし学習モデル。画像の局所的な部分の特徴に注目し、正常画像から逸脱しているかどうかを判定する。使用する際は多少の位置ズレは許容するが、基本的には全て位置合わせをする必要があり、画像サイズも統一しておかなければいけない。大幅な位置ズレや、回転に対しては誤分類の原因になる。
  algo2iTable: '
<table class="hacarus-table">
<thead>
  <tr class="tableizer-firstrow">
    <td><strong>パラメータ<strong></td>
    <td><strong>変数名<strong></td>
    <td><strong>型 : 範囲<strong></td>
    <td><strong>既定値<strong></td>
    <td><strong>計算時間への影響<strong></td>
    <td><strong>精度への影響<strong></td>
    <td><strong>備考<strong></td>
  </tr>
</thead>
<tbody>
 <tr><td>最小の検査サイズ</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(32, 32)</td><td>大 -> 大</td><td>-</td><td>(16, 16) or (32,32) or (64,64) が経験的によい。</td></tr>
 <tr><td>最小の検査サイズ幅</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>16</td><td>大 -> 小</td><td>大 -> 小</td><td>min_inspection_sizeの1/2か1/4が望ましい</td></tr>
 <tr><td>検知領域の異常度の閾値</td><td>threshold</td><td>float : [0, inf]</td><td>0.001</td><td>-</td><td>-</td><td>大きすぎるとほとんど正常、小さすぎるとほとんど異常</td></tr>
 <tr><td>無視される外周からの幅</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"外周からの無視する領域の幅 画像の縦, 横のピクセル数までの値にする。"</td></tr>
 <tr><td>最小の検知サイズ</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>検出される矩形の面積の下限</td></tr>
</tbody>
</table>
'
  algo3i: 'Pattern Matching'
  algo3iText: "We calculate the golden image from “OK” images (good samples, without defects, no annotation required) and compare it to reference. Hence, the position alignment is required (position variation is not allowed), and the size of all images must be the same. Misalignment and rotation might be a cause of misclassification."
  algo3iTable: '
<table class="hacarus-table">
<thead>
  <tr>
    <td><strong>Parameter</strong></td>
    <td><strong>Variable name</strong></td>
    <td><strong>Type: Range</strong></td>
    <td><strong>Default</strong></td>
    <td><strong>Impact on processing time</strong></td>
    <td><strong>Impact on accuracy</strong></td>
    <td><strong>Remarks</strong></td>
  </tr>
</thead>
<tbody>
<tr>
  <td>Minimum inspection size	</td>
  <td>min_inspection_size</td>
  <td>(int, int) : 0~height, 0~width</td>
  <td>(16, 16)</td>
  <td>large -> large</td>
  <td>-</td>
  <td>(16, 16) or (32, 32) or (64, 64) are empirically good.</td>
</tr>
<tr>
  <td>Minimum inspection step size</td>
  <td>min_inspection_step</td>
  <td>int : [1, inf]</td>
  <td>4</td>
  <td>large -> small</td>
  <td></td>
  <td>Half or quarter of min_inspection_size is desirable.</td>
</tr>
<tr>
  <td>Threshold of anomaly</td>
  <td>threshold</td>
  <td>float : [0, inf]	0.1</td>
  <td>-</td>
  <td>large->more tolerant</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>Width from the perimeter to be ignored</td>
  <td>ignore_outer</td>
  <td>(int, int) : 0~height, 0~width</td>
  <td>(0,0)</td>
  <td>-</td>
  <td>-</td>
  <td>The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image.</td>
</tr>
<tr>
  <td>Minimum detection size</td>
  <td>min_detected_area</td>
  <td>float : [1, inf]</td>
  <td>0</td>
  <td>-</td>
  <td>-</td>
  <td>Threshold of area of detected rectangle</td>
</tr>
<tr>
   <td>Anomaly range</td>
   <td>anomaly_range</td>
   <td>float : [0, 1]</td>
   <td>0</td>
   <td>-</td>
   <td>-</td>
   <td>Used to normalize heatmap colors across results.</td>
</tr>

</tbody></table>
'
  algo4i: 'Pattern Sample Inspection (Beta)'
  algo4iText: "A new, generic inspection algorithm that can handle inspection objects with different placement or rotation. We have seen good inspection results and very high inspection accuracy even with difficult inspection targets across customer projects."
  algo4iTable: '
<table class="hacarus-table">
<thead>
  <tr>
    <td><strong>Parameter</strong></td>
    <td><strong>Variable name</strong></td>
    <td><strong>Type: Range</strong></td>
    <td><strong>Default</strong></td>
    <td><strong>Impact on processing time</strong></td>
    <td><strong>Impact on accuracy</strong></td>
    <td><strong>Remarks</strong></td>
  </tr>
</thead>
<tbody>
<tr>
  <td>Model type</td>
  <td>model_type</td>
  <td>int : [0, 1]</td>
  <td>0</td>
  <td>small -> large</td>
  <td>-</td>
  <td>0 will use a small model. 1 will use a larger model.</td>
</tr>
<tr>
   <td>Number of Features</td>
   <td>num_features</td>
   <td>int : n</td>
   <td>100</td>
   <td>large -> large</td>
   <td>-</td>
   <td>100-n are empirically good.</td>
</tr>
<tr>
   <td>Threshold of anomaly</td>
   <td>threshold</td>
   <td>float : [0, inf]	0.1</td>
   <td>-</td>
   <td>large->more tolerant</td>
   <td></td>
   <td></td>
</tr>
<tr>
   <td>Width from the perimeter to be ignored</td>
   <td>ignore_outer</td>
   <td>(int, int) : 0~height, 0~width</td>
   <td>(0,0)</td>
   <td>-</td>
   <td>-</td>
   <td>The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image.</td>
</tr>
<tr>
   <td>Minimum detection size</td>
   <td>min_detected_area</td>
   <td>float : [1, inf]</td>
   <td>0</td>
   <td>-</td>
   <td>-</td>
   <td>Threshold area of detected rectangle</td>
</tr>
<tr>
   <td>Anomaly range</td>
   <td>anomaly_range</td>
   <td>float : [0, 1]</td>
   <td>0</td>
   <td>-</td>
   <td>-</td>
   <td>Used to normalize heatmap colors across results.</td>
</tr>

</tbody></table>
'
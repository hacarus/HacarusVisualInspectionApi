en:
  introduction: "Hacarus Visual Inspection Api"
  introductionMessage: "Hacarus is a provider of lightweight and explainable AI solutions for manufacturing and medical industries.
  <br/><br/>
  Our technology is based on Sparse Modeling, a Machine Learning technique that understands data like a human would - by its unique key features. Sparse Modeling is especially useful in resource constraint environments where computing power, cloud connection and availability of training data are limited – thanks to its lightweight design.
  <br/><br/>
  Our solutions can run in an offline environment on embedded systems or as a cloud module. Compared with conventional DL based approaches we are far more resource efficient and produce better results.
  <br/><br/>
  Visit <a href='https://hacarus.com/visual-inspection/'>https://hacarus.com/visual-inspection/</a> to learn more about Hacarus’ Visual Inspection solution or <a href='https://hacarus.com/contact/'>contact us</a> to request access to our API.
  "
  introductionMessageMoreCSharp: "This Visual Inspection Api wrapper for C#  is made for software engineers who want to integrate with the Hacarus Visual Inspection module through its API. The wrapper provides simple to use method calls for easy integration to your C# based applications. Supports .Net Framework 4.6.1 and .Net Core 2.0.
  "
  introductionMessageMorePython: "This Visual Inspection SDK for Python is made for software engineers who want to integrate with the Hacarus Visual Inspection module through its API. The wrapper provides simple to use method calls for easy integration to your Python based applications.
  "
  installation: "Installation"
  installationMessagePython: "To install this package on your project, use this command:"
  installationMessageCSharp: "To install this package on your project, use this command in Package Manager Console."
  installationMessageMoreCSharp: "
  You can also add it on your project by using `Add packages`, check on the `Show prerelease packages`, and search for `HacarusVisualInspectionApi` on the nuget.org repository.
  <br/><br/>
  Other installation options can be found on <a href='https://www.nuget.org/packages/HacarusVisualInspectionApi/1.1.2-beta'>Nuget Package Site</a>.
  "
  terms: "Terms"
  termsMessage: "A brief explanation of the terms used throughout this documentation:
<br/><br/>
<b>Model</b><br/>
A model is created (or trained) by applying an algorithm to a data-set of items (also called training-data), along with the configuration of a set of parameters.
After creation, the model can be used to analyze new data.
<br/><br/>
<b>Algorithm</b><br/>
The machine learning code that is used to build a model – selected depending on the nature of the visual inspection task and the expected precision and performance.
<br/><br/>
<b>Training</b><br/>
The process of creating a new model.
<br/><br/>
<b>Parameter</b><br/>
Parameters are used to configure how an algorithm should be applied during the training. For example the minimal or maximum accepted image resolution, etc.
<br/><br/>
<b>Item</b><br/>
An item represents the data of a single product that is the subject of the inspection. One item can have one or several images associated.
For example: A packaging box in a storage warehouse, with 6 images for each of the 6 box sides.
"
  usage: "Usage"
  usageMessage: "
To get started, you need the following:
<ul>
  <li>
    Client ID and Client Secret
    <ul>
      <li>
        These will be used to authorize the SDK.
      </li>
      <li>
        An authorized user will be able to access the system's functions, such as adding items, getting list of items, algorithms, and models.
      </li>
      <li>
        To be able to train models and to use the predict function, you also need an active license.
      </li>
    </ul>
  </li>
  <li>
    License File
    <ul>
      <li>
        These will be used to activate your license.
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    Training Images
    <ul>
      <li>
        A prerequisite to creating a new model, is to provide training items by uploading images.
      </li>
      <li>
        Use training items to create a model.
      </li>
      <li>
        Add items for prediction by uploading images.
      </li>
      <li>
        Use the created model to predict the items for prediction.
      </li>
      <li>
        Sample images for evaluation are available for download here: <a href='https://drive.google.com/open?id=1D736spz0rSOMgp9V71BEYtKH31Sxn1ud'>Metal Plates</a> and <a href='https://drive.google.com/open?id=14fnv6d9Cq9suUdoH57RntSuE_mh21fQg'>Wood Blocks</a>
        <ul>
          <li>
            Contains good and defect images and a list of parameters you may use to create a model.
          </li>
          <li>
            Images for training are located in a folder `train`, images for prediction are in `predict`
          </li>
          <li>
            NG means defect image, OK means good images
          </li>
        </ul>
      </li>
    </ul>
</ul>"
  initialization: "Initialization"
  initializationMessage: "
  <ul>
    <li>
      Initializes the library
    </li>
    <li>
      Use your endpoint URL as parameter
    </li>
    <li>
      If no endpoint is used, the library will use the default endpoint https://sdd-api.hacarus.com/api
    </li>
    <li>
      INDIVIDUAL endpoint URL will be provided by Hacarus on request
    </li>
  </ul>"
  authorization: "Authorization"
  authorizationMessage: "
  <ul>
    <li>
      Generates access token
    </li>
    <li>
      Use your Client ID and Client Secret as parameters
    </li>
    <li>
      Client ID and Client Secret will be provided by Hacarus on request
    </li>
  </ul>"
  sampleResponse: "Sample response"
  possibleErrors: "Possible errors"
  error401: " 401 Unauthorized:"
  invalidClientId: "Client ID is invalid"
  invalidClientSecret: "Client secret is invalid"
  methods: "Methods"
  activateLicense: "Activate License"
  activateLicenseMessage: "
  <ul>
    <li>
      Activates the license
    </li>
    <li>
      Customer ID and license file must be added as parameters
    </li>
    <li>
      License must be activated first before the user can use the train or predict functions
    </li>
    <li>
      To have a license file, please contact Hacarus
    </li>
  </ul>"
  error403: "403 Forbidden:"
  invalidLicense: "License file is invalid"
  licenseExists: "License is already active"
  getVersionNumber: "Get Version Number"
  getVersionNumberMessage: "Use this method to get the current version number of the Hacarus Visual Inspection API"
  getItems: "Get Items"
  getItemsMessage: "
  <ul>
    <li>
      Retrieves list of uploaded items grouped by training, predict, and archived
      <ul>
        <li>
          `training`: Items to be used for training
          <ul>
            <li>
              Check for key `good` to know if item is labeled as `%{true}`(good), `%{false}`(defect) or `%{null}` (unlabeled)
            </li>
          </ul>
        </li>
        <li>
          `predict`: Uploaded items that can be predicted
          <ul>
            <li>
              To check for labels and results, check for the keys `good` and `status`
            </li>
          </ul>
        </li>
        <li>
          `archived`: Achived items (Future feature, currently not in use)
        </li>
      </ul>
    </li>
    <li>
      `override_assessment` and `confirmed_assessment` are specific to UI and can be ignored when working with the SDK
    </li>
  </ul>
  "
  getAlgorithms:  "Get Algorithms"
  getAlgorithmsMessage: "
  <ul>
    <li>
      Returns list of available algorithms including parameters that can be used to create a model
    </li>
    <li>
      Algorithm documentation available <a href='https://hacarus.github.io/HacarusVisualInspectionApi/#t-algorithmswithversion'>here</a>
    </li>
  </ul>
  "
  possibleError: "Possible error"
  error404: "404 NotFound:"
  noAlgorithm: "No available algorithm. Please contact Hacarus if this problem occurs"
  getModels: "Get Models"
  getModelsMessage: "
  <ul>
    <li>
      Gets list of created models that can be used to predict items
    </li>
    <li>
      The key `active` means that if an item is predicted (using `%{serve}` method) without passing a model id, the model with `active` valued `%{true}` will be used as default
    </li>
    <li>
      The key `status` shows if a model is `active` or `failed.`
      <ul>
        <li>
          Models with `status: active` are successfully created and can be used for prediction
        </li>
        <li>
          Models with `status: failed` are not successfully created and cannot be used for prediction
        </li>
      </ul>
    </li>
  </ul>
  "
  train: "Train"
  algorithmParamter: "algorithm parameter"
  trainMessage: "
  <ul>
    <li>
      Creates model to use for prediction
    </li>
    <li>
      Accepts an optional parameter that contains array of item ids that will be used for training the model
    </li>
    <li>
      Accepts an optional parameter that contains array of %{algorithmParameter} for adjusting the algorithm settings
    </li>
    <li>
      To check the newly created model, use `%{getModels}` method
    </li>
  </ul>
  "
  invalidId: "Atleast one item id does not belong to the client, is invalid or does not exist."
  addItem: "Add Item"
  addItemMessage: "
  <ul>
    <li>
      Use this method to upload and label items for training
    </li>
    <li>
      To label items as good or defect, set `%{isGood}` parameter to a boolean value `%{true}`(good) or `%{false}`(defect)
    </li>
  </ul>
  "
  addItemMessageMoreCSharp: "
  <ul>
    <li>
      Use this method to upload items for prediction
    </li>
    <li>
      Use `Files` parameter to pass an array of `FileModel`. `FileModel` have properties `FileName` and `ContentType`.
    </li>
    <li>
      To create a FileModel, use `FileModel File = new FileModel()` or `FileModel File = new FileModel(\"FileName\", \"ContentType\")`
    </li>
    <li>
      To check the uploaded item, use the `GetItems()` method
    </li>
    <li>
      The filename of the image will be used as the `item_id` of the item
    </li>
    <li>
      Supported file types: `png`, `jpeg`, `tiff`
    </li>
  </ul>
  "
  addItemMessageMorePython: "
  <ul>
    <li>
      Use this method to upload items for prediction
    </li>
    <li>
      To check the uploaded item, use the `get_items()` method
    </li>
    <li>
      The filename of the image will be used as the `item_id` of the item
    </li>
    <li>
      Supported file types: `png`, `jpeg`, `tiff`
    </li>
  </ul>
  "
  error400: "400 BadRequest:"
  invalidFile: "Invalid file name or file type"
  noImage: "No image sent for upload"
  getItem: "Get Specific Item"
  getItemMessage: "
  <ul>
    <li>
      Get details of a specific item identified by its item ID
    </li>
    <li>
      The item ID is assigned during upload and based on the image file name
    </li>
    <li>
      Important keys:
      <ul>
        <li>
          `computed_assessment`: result of the prediction
        </li>
        <li>
          `annotations`: contains list of annotations generated when `%{serve}` method is called
        </li>
        <li>
          `raw_url`: url of your uploaded file
        </li>
        <li>
          `url`: processed file with defect annotations (green boxes)
        </li>
        <li>
          `status`: status of the item. It can be `pending`(not yet predicted or being predicted) or `done`(predicted)
        </li>
      </ul>
    </li>
  </ul>
  "
  itemIdDoesNotExists: "Item id does not exist"
  doesNotBelongToClient: "Item with the given item id does not belong to the client"
  predict: "Predict"
  predictMessage: "
  <ul>
    <li>
      Predicts if items are good or defect
    </li>
    <li>
      To check the result, use the `%{getItems}()` method and check for key `good` of each item
    </li>
  </ul>
  "
  itemDoesNotExists: "Item with item id sent does not exist"
  noModel: "No model available to use for prediction or available models have `failed` status. Create a new model by using `Train` method."
  genericErrors: "Generic Errors"
  errorUnauthorized: "Error when calling a method but not yet authorized. When encounted, please call `%{authorize}` method first."
  errorNoLicense: "Error when calling a method but license is not yet activated or expired. When encounted, please call `%{activateLicense}` method first."
  enLink: "./"
  jaLink: "./ja"
  algorithmsWithVersion: Algorithm V0.7.6
  algorithmOverview: Algorithm overview
  algorithmOverview1: Reconstructor Inspection
  algorithmOverview1i: "An unsupervised learning model that learns only from “OK” images (good samples, without defects, no annotation required)."
  algorithmOverview1ii: The model can learn global texture of images.
  algorithmOverview2: Local Pattern Inspection
  algorithmOverview2i: "An unsupervised learning model that learns only from “OK” images (good samples, without defects, no annotation required)."
  algorithmOverview2ii: The model can learn local structure of images.
  algorithmOverview3: 'Pattern Matching'
  algorithmOverview3i: 'Classical pattern matching algorithm which compares an image against a golden image.'
  algorithmDetails: "Algorithm details"
  algo1i: "Reconstructor Inspection"
  algo1iText: "An unsupervised learning model that learns only from “OK” images (good samples, without defects, annotations). At the time of prediction, a reconstruction error is calculated and abnormality defection is performed based on the magnitude. The model can learn global texture of images."
  algo1iTable: '
<table class="hacarus-table">
<thead>
 <tr>
  <td><strong>Parameter</strong></td>
  <td><strong>Variable name</strong></td>
  <td><strong>Type: Range</strong></td>
  <td><strong>Default</strong></td>
  <td><strong>Impact on processing time</strong></td>
  <td><strong>Impact on accuracy</strong></td>
  <td><strong>Remarks</strong></td>
 </tr>
</thead>
<tbody>
 <tr><td>Model size</td><td>train_size</td><td>int : [1, inf]</td><td>10000</td><td>large -> large</td><td>large -> large</td><td>&nbsp;</td></tr>
 <tr><td>Minimum inspection size</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(8, 8)</td><td>large -> large</td><td>-</td><td>(4, 4) or (8, 8) or (16, 16) are empirically good.</td></tr>
 <tr><td>Minimum inspection step size</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>4</td><td>large -> small</td><td>large -> small</td><td>"A divisor of min_inspection_size is desirable. 1 is the most computationally intensive, but the most efficient."</td></tr>
 <tr><td>Dimension of feature</td><td>n_components</td><td>int : [1, inf]</td><td>10</td><td>large -> large</td><td>large->more tolerant</td><td>If the dimension of the feature amount is large, even complex objects can be reconstructed.</td></tr>
 <tr><td>Number of algorithm iterations</td><td>max_iter</td><td>Int : [1, inf]</td><td>10</td><td>large -> large</td><td>-</td><td>If the amount is too small, the performance will be degraded, but if it is somewhat large, the performance will not change much. Number of algorithm iterations</td></tr>
 <tr><td>Reconstruction error threshold</td><td>reconstruct_thresh</td><td>float : [0, inf]</td><td>2</td><td>-</td><td>large->more tolerant</td><td>A threshold for reconstruction error, about 1.5 to 3 is empirically good</td></tr>
 <tr><td>Threshold of anomaly</td><td>threshold</td><td>float : [0, inf]</td><td>0.1</td><td>-</td><td>large->more tolerant</td><td>&nbsp;</td></tr>
 <tr><td>Width from the perimeter to be ignored</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image."</td></tr>
 <tr><td>Minimum detection size</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>Threshold of area of detected rectangle</td></tr>
</tbody></table>
'
  algo2i: "Local Pattern Inspection"
  algo2iText: "An unsupervised learning model that learns only from “OK” images (good samples, without defects, annotations). The model can learn local structure of images. Hence, the position alignment is required (minor gap is allowed), and the size of all images must be the same.
Misalignment and rotation might be a cause of misclassification."
  algo2iTable: '
<table class="hacarus-table">
<thead>
  <tr>
    <td><strong>Parameter</strong></td>
    <td><strong>Variable name</strong></td>
    <td><strong>Type: Range</strong></td>
    <td><strong>Default</strong></td>
    <td><strong>Impact on processing time</strong></td>
    <td><strong>Impact on accuracy</strong></td>
    <td><strong>Remarks</strong></td>
  </tr>
</thead>
<tbody>
 <tr><td>Minimum inspection size</td><td>min_inspection_size</td><td>(int, int) : 0~height, 0~width</td><td>(32, 32)</td><td>large -> large</td><td>-</td><td>(16, 16) or (32, 32) or (64, 64) are empirically good.</td></tr>
 <tr><td>Minimum inspection step size</td><td>min_inspection_step</td><td>int : [1, inf]</td><td>16</td><td>large -> small</td><td>large -> small</td><td>Half or quarter of min_inspection_size is desirable.</td></tr>
 <tr><td>Threshold of anomaly</td><td>threshold</td><td>float : [0, inf]</td><td>0.001</td><td>-</td><td>large->more tolerant</td><td>&nbsp;</td></tr>
 <tr><td>Width from the perimeter to be ignored</td><td>ignore_outer</td><td>(int, int) : 0~height, 0~width</td><td>(0,0)</td><td>-</td><td>-</td><td>"The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image."</td></tr>
 <tr><td>Minimum detection size</td><td>min_detected_area</td><td>Float : [1, inf]</td><td>0</td><td>-</td><td>-</td><td>Threshold of area of detected rectangle</td></tr>
</tbody></table>
'
  algo3i: 'Pattern Matching'
  algo3iText: "We calculate the golden image from “OK” images (good samples, without defects, no annotation required) and compare it to reference. Hence, the position alignment is required (position variation is not allowed), and the size of all images must be the same. Misalignment and rotation might be a cause of misclassification."
  algo3iTable: '
<table class="hacarus-table">
<thead>
  <tr>
    <td><strong>Parameter</strong></td>
    <td><strong>Variable name</strong></td>
    <td><strong>Type: Range</strong></td>
    <td><strong>Default</strong></td>
    <td><strong>Impact on processing time</strong></td>
    <td><strong>Impact on accuracy</strong></td>
    <td><strong>Remarks</strong></td>
  </tr>
</thead>
<tbody>
<tr>
  <td>Minimum inspection size	</td>
  <td>min_inspection_size</td>
  <td>(int, int) : 0~height, 0~width</td>
  <td>(16, 16)</td>
  <td>large -> large</td>
  <td>-</td>
  <td>(16, 16) or (32, 32) or (64, 64) are empirically good.</td>
</tr>
<tr>
  <td>Minimum inspection step size</td>
  <td>min_inspection_step</td>
  <td>int : [1, inf]</td>
  <td>4</td>
  <td>large -> small</td>
  <td></td>
  <td>Half or quarter of min_inspection_size is desirable.</td>
</tr>
<tr>
  <td>Threshold of anomaly</td>
  <td>threshold</td>
  <td>float : [0, inf]	0.1</td>
  <td>-</td>
  <td>large->more tolerant</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>Width from the perimeter to be ignored</td>
  <td>ignore_outer</td>
  <td>(int, int) : 0~height, 0~width</td>
  <td>(0,0)</td>
  <td>-</td>
  <td>-</td>
  <td>The width of the ignored area from the perimeter. Use values up to the number of vertical and horizontal pixels in the image.</td>
</tr>
<tr>
  <td>Minimum detection size</td>
  <td>min_detected_area</td>
  <td>float : [1, inf]</td>
  <td>0</td>
  <td>-</td>
  <td>-</td>
  <td>Threshold of area of detected rectangle</td>
</tr>

</tbody></table>
'
